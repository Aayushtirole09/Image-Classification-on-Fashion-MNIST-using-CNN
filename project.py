# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DbulFcDB-MA7xgpnSUALR4lvChyqka4T
"""

# Import libraries
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import fashion_mnist
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report


#  Load dataset (auto-downloads from internet)
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

#  Preprocess
# Normalize to [0, 1]
x_train = x_train / 255.0
x_test = x_test / 255.0

# Reshape to add channel dimension (28x28 â†’ 28x28x1)
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)

# Class labels
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

#  Build CNN Model
model = models.Sequential([
    tf.keras.Input(shape=(28, 28, 1)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dropout(0.4),
    layers.Dense(128, activation='relu'),
    layers.Dense(10, activation='softmax')
])


#  Compile
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

#  Train
history = model.fit(x_train, y_train, epochs=10, validation_split=0.1)

#  Evaluate
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f'\n Test Accuracy: {test_acc * 100:.2f}%')


#  Final Evaluation Metrics (Accuracy, Precision, Recall)
y_pred_probs = model.predict(x_test)
y_pred = np.argmax(y_pred_probs, axis=1)

# Metrics
acc = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)

print("\n Final Evaluation Metrics:")
print(f"Accuracy : {acc * 100:.2f}%")
print(f"Precision: {precision * 100:.2f}%")
print(f"Recall   : {recall * 100:.2f}%")

# Optional: Classification report
print("\n Classification Report:")
print(classification_report(y_test, y_pred, target_names=class_names, zero_division=0))


# Plotting Figure 1
plt.figure(figsize=(12, 5))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Training and Validation Accuracy (Fig. 1a)')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Training and Validation Loss (Fig. 1b)')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()


#  Predict and show sample results
predictions = model.predict(x_test)

def show_prediction(i):
    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')
    true_label = class_names[y_test[i]]
    predicted_label = class_names[np.argmax(predictions[i])]
    plt.title(f'True: {true_label}\nPredicted: {predicted_label}')
    plt.axis('off')
    plt.show()

# Show a few predictions
for i in range(10):
    show_prediction(i)